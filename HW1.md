## Задание:

Ознакомиться с библиотеками для распараллеливания задач в Python:
1. `multiprocessing`
2. `joblib`
3. `dask`


Каждая из указанных библиотек для распараллеливания задач в Python имеет свои особенности и области применения. Вот краткий обзор каждой из них:

### 1. `multiprocessing`

**Описание**:
- Встроенная библиотека Python для параллельного выполнения задач.
- Создает отдельные процессы, которые могут выполняться параллельно и независимо друг от друга.
- Каждый процесс имеет свое собственное пространство памяти, что позволяет избежать проблем с глобальной интерпретаторной блокировкой (GIL).

**Основные компоненты**:
- `Process`: для создания и управления отдельными процессами.
- `Pool`: для управления пулом процессов и выполнения задач в параллельных процессах.
- `Queue` и `Pipe`: для межпроцессного взаимодействия.

**Пример использования**:

```python
from multiprocessing import Pool

def square(x):
    return x * x

if __name__ == '__main__':
    with Pool(4) as p:
        results = p.map(square, [1, 2, 3, 4, 5])
    print(results)
```

**Преимущества**:
- Подходит для CPU-bound задач.
- Прост в использовании для базовых случаев.

**Ограничения**:
- Процессы создаются с некоторыми накладными расходами.
- Использование может быть сложным для задач с большим объемом данных, из-за необходимости обмена данными между процессами.

### 2. `joblib`

**Описание**:
- Библиотека для параллельного выполнения задач, особенно полезная в контексте машинного обучения и научных вычислений.
- Основное внимание уделяет удобству сохранения и загрузки данных, а также поддерживает кэширование результатов.

**Основные компоненты**:
- `Parallel`: для распараллеливания вычислений.
- `delayed`: для ленивого выполнения функций.

**Пример использования**:

```python
from joblib import Parallel, delayed

def square(x):
    return x * x

results = Parallel(n_jobs=4)(delayed(square)(i) for i in [1, 2, 3, 4, 5])
print(results)
```

**Преимущества**:
- Прост в использовании, особенно в контексте машинного обучения.
- Поддержка кэширования результатов и удобная работа с большими массивами данных.

**Ограничения**:
- Для некоторых задач может быть менее гибким, чем `multiprocessing` или `dask`.

### 3. `dask`

**Описание**:
- Более сложная библиотека для параллельных и распределенных вычислений.
- Подходит для масштабируемых вычислений и обработки больших объемов данных.

**Основные компоненты**:
- `dask.delayed`: для ленивых вычислений.
- `dask.distributed`: для распределенных вычислений на нескольких узлах.
- `dask.array` и `dask.dataframe`: для обработки больших массивов данных и таблиц, аналогичных NumPy и Pandas.

**Пример использования**:

```python
import dask.array as da

# Создание большого массива
x = da.random.random((10000, 10000), chunks=(1000, 1000))

# Выполнение вычислений
result = x.sum().compute()
print(result)
```

**Преимущества**:
- Поддержка распределенных вычислений на кластерах.
- Подходит для обработки больших объемов данных, которые не помещаются в память.

**Ограничения**:
- Может быть избыточным для простых задач.
- Имеет более сложный API и может требовать дополнительных настроек для распределенных вычислений.

### Сравнение и выбор:

- **`multiprocessing`**: Хорош для простых задач с ограниченным количеством данных, где требуется параллельное выполнение.
- **`joblib`**: Отлично подходит для задач, связанных с машинным обучением и научными вычислениями, с удобным интерфейсом и поддержкой кэширования.
- **`dask`**: Подходит для больших объемов данных и распределенных вычислений, предоставляет гибкий и масштабируемый подход для обработки данных.

Выбор библиотеки зависит от конкретных требований проекта, объема данных и сложности вычислений.
